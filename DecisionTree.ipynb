{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ML final project\n",
    "## 張皓丞 10811017\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/chc/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from text_preprocessing import preprocess_text\n",
    "from text_preprocessing import to_lower, remove_itemized_bullet_and_numbering, remove_punctuation, remove_whitespace, normalize_unicode,remove_stopword, substitute_token,lemmatize_word\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import the dataset and explore them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataX = pd.read_excel(\"MLdata/Dataset1_train/X_train.xlsx\")\n",
    "dataY = pd.read_excel(\"MLdata/Dataset1_train/y_train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dataX[dataX.columns[0]],bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dataX[dataX.columns[6]],bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing Part\n",
    "Implement the kNN algorithm to impute the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 21.42it/s]\n"
     ]
    }
   ],
   "source": [
    "def kneighbors(k, rowsWithNum,df_rescale, df):\n",
    "    indices = {}\n",
    "    df_withNun = df.loc[rowsWithNum].apply(minmax_scale)\n",
    "    for row in rowsWithNum:\n",
    "        distances = np.sqrt(((df_rescale - df_withNun.loc[row]) ** 2).sum(axis=1))\n",
    "        indices.update( {row:distances.sort_values()[:k].index})\n",
    "    return indices\n",
    "\n",
    "def knn_imputation(df, k=5):\n",
    "    df_imputed = df.copy()\n",
    "    df_withoutNun = df[~df.isnull().any(axis=1)]\n",
    "    df_rescale = df_withoutNun.apply(minmax_scale)\n",
    "    for feature in tqdm.tqdm(df.columns,position=0,leave=True):\n",
    "        rowsWithNum = df[df[feature].isnull()].index\n",
    "        indices = kneighbors(k,rowsWithNum,df_rescale,df)\n",
    "        for key in indices:\n",
    "            imputed = df.loc[indices[key],feature].mean().round(2)\n",
    "            df_imputed[feature].iloc[[key]] = imputed\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "dataX_imputed = knn_imputation(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataY_outlier = dataY[(np.abs(stats.zscore(dataX_imputed)) < 3).all(axis=1)]\n",
    "dataX_outlier = dataX_imputed[(np.abs(stats.zscore(dataX_imputed)) < 3).all(axis=1)]\n",
    "dataX_outlier.reset_index(drop=True,inplace=True)\n",
    "dataY_outlier.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using the Random Over Sample to deal with the imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy='auto')\n",
    "X_ros, Y_ros = ros.fit_resample(dataX_outlier,dataY_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#SMOTE = SMOTE(sampling_strategy='auto')\n",
    "X_res = pd.read_csv('X_res.csv')\n",
    "X_res.drop(X_res.columns[0],axis=1, inplace = True)\n",
    "Y_res = pd.read_csv('Y_res.csv')\n",
    "Y_res.drop(Y_res.columns[0],axis=1, inplace = True)\n",
    "Y_res.rename(columns={'class':'target'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building Tree\n",
    "### First version\n",
    "First define the formula of entropy and information_gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(counts):\n",
    "    # Calculate the entropy of the target variable\n",
    "    n = sum(counts)\n",
    "    ent = 0\n",
    "    for count in counts:\n",
    "        p = count / n\n",
    "        ent -= p * math.log(p, 2)\n",
    "    return ent\n",
    "def information_gain(df,df_left, df_right):\n",
    "\n",
    "    left_entropy = entropy(df_left.target.value_counts())\n",
    "    right_entropy = entropy(df_right.target.value_counts())\n",
    "\n",
    "\n",
    "    total_size = len(df_left) + len(df_right)\n",
    "    left_weight = len(df_left) / total_size\n",
    "    right_weight = len(df_right) / total_size\n",
    "    weighted_avg_entropy = left_weight * left_entropy + right_weight * right_entropy\n",
    "\n",
    "\n",
    "    parent_entropy = entropy(df.target.value_counts())\n",
    "    info_gain = parent_entropy - weighted_avg_entropy\n",
    "\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creat a Node as the root. And use the IG as the standard to choose the best feature and threshold to split the node\n",
    "When the tree is reach the max_depth or min_samples_at_leaf or only remain less than 2 classes, stop and store the target in the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, target=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.target = target\n",
    "\n",
    "def create_tree(df, max_depth=5, min_samples_at_leaf=5):\n",
    "    if len(df.target.unique()) <= 2 or max_depth == 0:\n",
    "        return Node(target=int(df.target.mode().loc[0]))\n",
    "    else:\n",
    "        features = df.columns[:-1]\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gain = 0\n",
    "        for feature in features:\n",
    "            values = df[feature].unique()\n",
    "            for value in values:\n",
    "                if value == values.max():\n",
    "                    threshold = values.max()\n",
    "                else:\n",
    "                    threshold = (value + values[values > value].min()) / 2\n",
    "                df_left = df[df[feature] <= threshold]\n",
    "                df_right = df[df[feature] > threshold]\n",
    "                gain = information_gain(df,df_left, df_right)\n",
    "                if gain > best_gain:\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_gain = gain\n",
    "        df_left = df[df[best_feature] <= best_threshold]\n",
    "        df_right = df[df[best_feature] > best_threshold]\n",
    "        if len(df_left) < min_samples_at_leaf or len(df_right) < min_samples_at_leaf:\n",
    "            return Node(target=int(df.target.mode().loc[0]))\n",
    "        left = create_tree(df_left,max_depth=max_depth-1, min_samples_at_leaf=min_samples_at_leaf)\n",
    "        right = create_tree(df_right,max_depth=max_depth-1, min_samples_at_leaf=min_samples_at_leaf)\n",
    "        return Node(feature=best_feature, threshold = best_threshold, left=left, right=right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(dataX_outlier, dataY_outlier, test_size=0.2, stratify=dataY_outlier)\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "y_val.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree = create_tree(pd.concat([X_train, y_train], axis=1), max_depth=12, min_samples_at_leaf=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tree,x):\n",
    "    while tree.target == None:\n",
    "        feature = tree.feature\n",
    "        threshold = tree.threshold\n",
    "        if x[feature] <= threshold:\n",
    "            tree = tree.left\n",
    "        else:\n",
    "            tree = tree.right\n",
    "    return tree.target\n",
    "\n",
    "def predictAns(tree, X):\n",
    "    predictions = []\n",
    "    for index in tqdm.trange(len(X)):\n",
    "        predictions.append(predict(tree, X.loc[index]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluate Part\n",
    "make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pre = predictAns(tree,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def report(predictions, y_test):\n",
    "    print('Accuracy: %s' % accuracy_score(y_test, predictions))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, predictions,labels=[3,4,5,6,7,8]))\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5698924731182796\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  4  2  0  0]\n",
      " [ 0  1 45 32  0  0]\n",
      " [ 0  4 16 52  5  0]\n",
      " [ 0  0  6  7  9  0]\n",
      " [ 0  0  2  0  0  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.61      0.58      0.59        78\n",
      "           6       0.56      0.68      0.61        77\n",
      "           7       0.64      0.41      0.50        22\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.57       186\n",
      "   macro avg       0.30      0.28      0.28       186\n",
      "weighted avg       0.56      0.57      0.56       186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(pre,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Second version\n",
    "Add boosting into the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use this function to calculate the error base on the last weak learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tree,x):\n",
    "    while tree.target == None:\n",
    "        feature = tree.feature\n",
    "        threshold = tree.threshold\n",
    "        if x[feature] <= threshold:\n",
    "            tree = tree.left\n",
    "        else:\n",
    "            tree = tree.right\n",
    "    return tree.target\n",
    "\n",
    "def predictAns(tree, X):\n",
    "    predictions = []\n",
    "    for index in range(len(X)):\n",
    "        predictions.append(predict(tree, X.loc[index]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use a function weight_sum to calculate the sum of weight of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def weight_sum(df):\n",
    "    weight_dic = {3:0,4:0,5:0,6:0,7:0,8:0}\n",
    "    for index in df.index:\n",
    "        weight_dic[df.target[index]] += df.weights[index]\n",
    "    for key in range(3,9):\n",
    "        if weight_dic[key] == 0:\n",
    "            weight_dic.pop(key)\n",
    "    return weight_dic\n",
    "\n",
    "def entropy(df):\n",
    "    n = sum(df.weights)\n",
    "    ent = 0\n",
    "    weight_dic = weight_sum(df)\n",
    "    for key in weight_dic:\n",
    "        p = weight_dic[key] / n\n",
    "        ent -=   p * math.log(p, 2)\n",
    "    return ent\n",
    "\n",
    "def information_gain(df, df_left, df_right):\n",
    "    left_entropy = entropy(df_left)\n",
    "    right_entropy = entropy(df_right)\n",
    "\n",
    "    total_size = len(df_left) + len(df_right)\n",
    "\n",
    "    left_weight = len(df_left) / total_size\n",
    "    right_weight = len(df_right) / total_size\n",
    "\n",
    "    weighted_avg_entropy = left_weight * left_entropy + right_weight * right_entropy\n",
    "    parent_entropy = entropy(df)\n",
    "    info_gain = parent_entropy - weighted_avg_entropy\n",
    "\n",
    "    return info_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, target=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.target = target\n",
    "\n",
    "def create_tree(df, weights, max_depth=5, min_samples_at_leaf=5):\n",
    "    if len(df.target.unique()) <= 2 or max_depth == 0:\n",
    "        return Node(target=int(df.target.mode().loc[0]))\n",
    "    else:\n",
    "        df['weights'] = weights[df.index]\n",
    "        features = df.columns[:-2]\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gain = 0\n",
    "        for feature in features:\n",
    "            values = df[feature].unique()\n",
    "            for value in values:\n",
    "                if value == values.max():\n",
    "                    threshold = values.max()\n",
    "                else:\n",
    "                    threshold = (value + values[values > value].min()) / 2\n",
    "                df_left = df[df[feature] <= threshold]\n",
    "                df_right = df[df[feature] > threshold]\n",
    "                gain = information_gain(df,df_left, df_right)\n",
    "                if gain > best_gain:\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_gain = gain\n",
    "        df_left = df[df[best_feature] <= best_threshold]\n",
    "        df_right = df[df[best_feature] > best_threshold]\n",
    "        if len(df_left) < min_samples_at_leaf or len(df_right) < min_samples_at_leaf:\n",
    "            return Node(target=int(df.target.mode().loc[0]))\n",
    "        left = create_tree(df_left, weights, max_depth=max_depth-1, min_samples_at_leaf=min_samples_at_leaf)\n",
    "        right = create_tree(df_right, weights, max_depth=max_depth-1, min_samples_at_leaf=min_samples_at_leaf)\n",
    "        return Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Calculate the error to update the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def boost(X, y, num_iterations=50):\n",
    "    example_weights = np.ones(len(y)) / len(y)\n",
    "    weak_learners = []\n",
    "    for i in tqdm.trange(num_iterations,position=0,leave=True):\n",
    "        tree = create_tree(pd.concat([X, y], axis=1),weights=example_weights, max_depth=12, min_samples_at_leaf=3)\n",
    "        prediction = predictAns(tree, X)\n",
    "        error = np.average(prediction != np.array(y.target), weights=example_weights)\n",
    "        if error >= 0.5:\n",
    "            break\n",
    "        beta = error / (1 - error)\n",
    "        for index in range(len(example_weights)):\n",
    "            if prediction[index] == y.target.loc[index]:\n",
    "                example_weights[index] *= beta\n",
    "        example_weights /= np.sum(example_weights)\n",
    "        weak_learners.append((beta, tree))\n",
    "    return weak_learners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To predict the final answer. The instance with higest weighted vote is the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def strong_learner_preadict(weak_learners,x):\n",
    "    weight_dic = {3:0,4:0,5:0,6:0,7:0,8:0}\n",
    "    for beta,tree in weak_learners:\n",
    "        pre = predict(tree,x)\n",
    "        weight_dic[pre] += np.log(1/beta)\n",
    "    max=0\n",
    "    target = None\n",
    "    for key in weight_dic:\n",
    "        if weight_dic[key] > max:\n",
    "            max = weight_dic[key]\n",
    "            target = key\n",
    "    return target\n",
    "\n",
    "def SL_preadictAns(weak_learners,x):\n",
    "    predictions = []\n",
    "    for index in tqdm.trange(len(x),position=0,leave=True):\n",
    "        predictions.append(strong_learner_preadict(weak_learners, x.loc[index]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [06:49<11:57, 102.47s/it]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(dataX_outlier, dataY_outlier, test_size=0.2, stratify=dataY_outlier)\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "y_val.reset_index(drop=True,inplace=True)\n",
    "dataY_outlier.reset_index(drop=True,inplace=True)\n",
    "weak_learners = boost(X_train, y_train,num_iterations=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:00<00:00, 5078.94it/s]\n"
     ]
    }
   ],
   "source": [
    "pre2 = SL_preadictAns(weak_learners,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def report(predictions, y_test):\n",
    "    print('Accuracy: %s' % accuracy_score(y_test, predictions))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, predictions,labels=[3,4,5,6,7,8]))\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7849462365591398\n",
      "Confusion Matrix:\n",
      "[[ 1  0  0  0  0  0]\n",
      " [ 0  3  3  0  0  0]\n",
      " [ 0  0 66 12  0  0]\n",
      " [ 0  0 14 60  3  0]\n",
      " [ 0  2  0  4 16  0]\n",
      " [ 0  0  0  2  0  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       0.60      0.50      0.55         6\n",
      "           5       0.80      0.85      0.82        78\n",
      "           6       0.77      0.78      0.77        77\n",
      "           7       0.84      0.73      0.78        22\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.78       186\n",
      "   macro avg       0.67      0.64      0.65       186\n",
      "weighted avg       0.78      0.78      0.78       186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(pre2,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Predict the test dataset and save as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 64.66it/s]\n",
      "100%|██████████| 256/256 [00:00<00:00, 5981.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dataTest = pd.read_excel('MLdata/Dataset1_test/X_test.xlsx')\n",
    "dataTest = knn_imputation(dataTest)\n",
    "d1ans = SL_preadictAns(bestModel,dataTest)\n",
    "ans=pd.DataFrame(columns=[\"index\",\"target\"])\n",
    "for i,pre in enumerate(d1ans):\n",
    "    ans.loc[i] = [i,int(pre)]\n",
    "ans.to_csv(\"d1ans.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(counts):\n",
    "    # Calculate the entropy of the target variable\n",
    "    n = sum(counts)\n",
    "    ent = 0\n",
    "    for count in counts:\n",
    "        p = count / n\n",
    "        ent -= p * math.log(p, 2)\n",
    "    return ent\n",
    "def information_gain(df,df_left, df_right):\n",
    "\n",
    "    left_entropy = entropy(df_left.target.value_counts())\n",
    "    right_entropy = entropy(df_right.target.value_counts())\n",
    "\n",
    "\n",
    "    total_size = len(df_left) + len(df_right)\n",
    "    left_weight = len(df_left) / total_size\n",
    "    right_weight = len(df_right) / total_size\n",
    "    weighted_avg_entropy = left_weight * left_entropy + right_weight * right_entropy\n",
    "\n",
    "\n",
    "    parent_entropy = entropy(df.target.value_counts())\n",
    "    info_gain = parent_entropy - weighted_avg_entropy\n",
    "\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, target=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.target = target\n",
    "\n",
    "def create_tree(df, max_depth=5, min_samples_at_leaf=5):\n",
    "    if len(df.target.unique()) <= 2 or max_depth == 0:\n",
    "        return Node(target=int(df.target.mode().loc[0]))\n",
    "    else:\n",
    "        features = df.columns[:-1]\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gain = 0\n",
    "        for feature in features:\n",
    "            values = df[feature].unique()\n",
    "            num_values = round(len(values)**(1/3)**2)\n",
    "            min = np.min(values)\n",
    "            max = np.max(values)\n",
    "            interval = (max - min + 1)/num_values\n",
    "            values = [round(min + i*interval,2) for i in range(num_values)]\n",
    "            for value in values:\n",
    "                # if value == max:\n",
    "                #     threshold = values.max()\n",
    "                # else:\n",
    "                #     threshold = (value + values[values > value].min()) / 2\n",
    "                threshold = value\n",
    "                df_left = df[df[feature] <= threshold]\n",
    "                df_right = df[df[feature] > threshold]\n",
    "                gain = information_gain(df,df_left, df_right)\n",
    "                if gain > best_gain:\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_gain = gain\n",
    "        if best_feature==None:\n",
    "            df.to_csv('temp.csv')\n",
    "            # print(df.value_counts())\n",
    "            # print(df)\n",
    "            # print(df.target.unique())\n",
    "            return Node(target=int(df.target.mode().loc[0]))\n",
    "        df_left = df[df[best_feature] <= best_threshold]\n",
    "        df_right = df[df[best_feature] > best_threshold]\n",
    "        if len(df_left) < min_samples_at_leaf or len(df_right) < min_samples_at_leaf:\n",
    "            return Node(target=int(df.target.mode().loc[0]))\n",
    "        left = create_tree(df_left,max_depth=max_depth-1, min_samples_at_leaf=min_samples_at_leaf)\n",
    "        right = create_tree(df_right,max_depth=max_depth-1, min_samples_at_leaf=min_samples_at_leaf)\n",
    "        return Node(feature=best_feature, threshold = best_threshold, left=left, right=right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tree,x):\n",
    "\n",
    "    while tree.target == None:\n",
    "        feature = tree.feature\n",
    "        threshold = tree.threshold\n",
    "        if x[feature] <= threshold:\n",
    "            tree = tree.left\n",
    "        else:\n",
    "            tree = tree.right\n",
    "    return tree.target\n",
    "\n",
    "def predictAns(tree, X):\n",
    "    predictions = []\n",
    "    for index in tqdm.trange(len(X)):\n",
    "        predictions.append(predict(tree, X.loc[index]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124848/124848 [00:34<00:00, 3605.32it/s]\n"
     ]
    }
   ],
   "source": [
    "dataX = pd.read_excel(\"MLdata/Dataset2_train/X_train.xlsx\")\n",
    "dataY = pd.read_excel(\"MLdata/Dataset2_train/y_train.xlsx\")\n",
    "processing_function_list = [to_lower,\n",
    "                            remove_itemized_bullet_and_numbering,\n",
    "                            remove_punctuation,\n",
    "                            remove_whitespace,\n",
    "                            normalize_unicode,\n",
    "                            remove_stopword,\n",
    "                            substitute_token,\n",
    "                            lemmatize_word]\n",
    "dataX = [str(x) for x in dataX.Phrase]\n",
    "dataX = [preprocess_text(x,processing_function_list) for x in tqdm.tqdm(dataX,position=0,leave=True)]\n",
    "vectoriser = TfidfVectorizer(max_features=7000)\n",
    "dataX = vectoriser.fit_transform(dataX)\n",
    "dataX = pd.DataFrame(dataX.toarray(),columns=vectoriser.get_feature_names())\n",
    "X_train, X_val, y_train, y_val = train_test_split(dataX, dataY, test_size=0.2, stratify=dataY)\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "y_val.reset_index(drop=True,inplace=True)\n",
    "dataY_outlier.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree = create_tree(pd.concat([X_train, y_train], axis=1), max_depth=12, min_samples_at_leaf=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def report(predictions, y_test):\n",
    "    print('Accuracy: %s' % accuracy_score(y_test, predictions))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, predictions,labels=[0,1,2,3,4]))\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30865/30865 [00:01<00:00, 19076.12it/s]\n"
     ]
    }
   ],
   "source": [
    "pre = predictAns(tree,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5050704681678276\n",
      "Confusion Matrix:\n",
      "[[    0     0  1414     0     0]\n",
      " [    0     0  5448     0     0]\n",
      " [    0     0 15589     0     0]\n",
      " [    0     0  6573     0     0]\n",
      " [    0     0  1841     0     0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1414\n",
      "           1       0.00      0.00      0.00      5448\n",
      "           2       0.51      1.00      0.67     15589\n",
      "           3       0.00      0.00      0.00      6573\n",
      "           4       0.00      0.00      0.00      1841\n",
      "\n",
      "    accuracy                           0.51     30865\n",
      "   macro avg       0.10      0.20      0.13     30865\n",
      "weighted avg       0.26      0.51      0.34     30865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(pre,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      " 82%|████████▏ | 9/11 [00:00<00:00, 85.92it/s]/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:464: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/chc/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:465: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "/var/folders/5x/dbx2lv556_g0h2jsjg7k_tf00000gn/T/ipykernel_8228/1232496976.py:6: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  indices.update( {row:distances.sort_values()[:k].index})\n",
      "100%|██████████| 11/11 [00:00<00:00, 86.89it/s]\n"
     ]
    }
   ],
   "source": [
    "dataTest = pd.read_excel('MLdata/Dataset2_test/X_test.xlsx')\n",
    "dataTest = knn_imputation(dataTest)\n",
    "d2ans = predictAns(tree,dataTest)\n",
    "ans=pd.DataFrame(columns=[\"index\",\"Sentiment])\n",
    "for i,pre in enumerate(d2ans):\n",
    "    ans.loc[i] = [i,int(pre)]\n",
    "ans.to_csv(\"d2ans.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
